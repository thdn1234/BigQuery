{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a15b6c1ff03f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Create a \"Client\" object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbigquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"openaq\" dataset\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# List all the tables in the \"hacker_news\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there are four!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)\n",
    "\n",
    "list_of_tables = [table.table_id for table in tables]\n",
    "\n",
    "# Construct a reference to the \"global_air_quality\" table\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"global_air_quality\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "### 1) Units of measurement\n",
    "\n",
    "Which countries have reported pollution levels in units of \"ppm\"?  In the code cell below, set `first_query` to an SQL query that pulls the appropriate entries from the `country` column.\n",
    "\n",
    "In case it's useful to see an example query, here's some code from the tutorial:\n",
    "\n",
    "```\n",
    "query = \"\"\"\n",
    "        SELECT city\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select countries with units of \"ppm\"\n",
    "first_query = \"\"\"\n",
    "              SELECT country\n",
    "              FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "              WHERE unit = 'ppm'\n",
    "              \"\"\" # Your code goes here\n",
    "\n",
    "# Set up the query (cancel the query if it would use too much of \n",
    "# your quota, with the limit set to 10 GB)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "first_query_job = client.query(first_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query, and return a pandas DataFrame\n",
    "first_results = first_query_job.to_dataframe()\n",
    "\n",
    "# View top few rows of results\n",
    "print(first_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) High air quality\n",
    "\n",
    "Which pollution levels were reported to be exactly 0?  \n",
    "- Set `zero_pollution_query` to select **all columns** of the rows where the `value` column is 0.\n",
    "- Set `zero_pollution_results` to a pandas DataFrame containing the query results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to select all columns where pollution levels are exactly 0\n",
    "zero_pollution_query = \"\"\"\n",
    "                       SELECT *\n",
    "                       FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "                       WHERE value = 0\n",
    "                       \"\"\" # Your code goes here\n",
    "# ONE_MB = 1000*1000\n",
    "# ONE_GB = 1000*1000*1000\n",
    "\n",
    "# Set up the query\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(zero_pollution_query, job_config=safe_config)\n",
    "\n",
    "# API request - run the query and return a pandas DataFrame\n",
    "zero_pollution_results = query_job.to_dataframe() # Your code goes here\n",
    "\n",
    "print(zero_pollution_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT parent, COUNT(1) AS NumPosts\n",
    "        FROM `bigquery-public-data.hacker_news.comments`\n",
    "        GROUP BY parent\n",
    "        HAVING COUNT(1) > 10\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to find out the number of accidents for each day of the week\n",
    "query = \"\"\"\n",
    "        SELECT COUNT(consecutive_number) AS num_accidents, \n",
    "               EXTRACT(DAYOFWEEK FROM timestamp_of_crash) AS day_of_week\n",
    "        FROM `bigquery-public-data.nhtsa_traffic_fatalities.accident_2015`\n",
    "        GROUP BY day_of_week\n",
    "        ORDER BY num_accidents DESC\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_per_month_query = \"\"\"\n",
    "                        SELECT EXTRACT(MONTH FROM trip_start_timestamp) AS month, COUNT(1) AS num_trips\n",
    "                        FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                        WHERE EXTRACT(YEAR FROM trip_start_timestamp) = 2017\n",
    "                        GROUP BY month\n",
    "                        ORDER BY month\n",
    "                        \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeds_query = \"\"\"\n",
    "               WITH RelevantRides AS\n",
    "               (\n",
    "                   SELECT EXTRACT(HOUR FROM trip_start_timestamp) AS hour_of_day,\n",
    "                          trip_miles, \n",
    "                          trip_seconds\n",
    "                   FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "                   WHERE trip_start_timestamp > '2017-01-01' AND \n",
    "                         trip_start_timestamp < '2017-07-01' AND \n",
    "                         trip_seconds > 0 AND \n",
    "                         trip_miles > 0\n",
    "                   \n",
    "               )\n",
    "               SELECT hour_of_day, \n",
    "               COUNT(1) AS num_trips,\n",
    "               3600 * SUM(trip_miles) / SUM(trip_seconds) AS avg_mph\n",
    "               FROM RelevantRides\n",
    "               GROUP BY hour_of_day\n",
    "               ORDER BY hour_of_day\n",
    "               \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers_query = \"\"\"\n",
    "                SELECT a.id, a.body, a.owner_user_id\n",
    "                FROM `bigquery-public-data.stackoverflow.posts_questions` AS q \n",
    "                INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                    ON q.id = a.parent_id\n",
    "                WHERE q.tags LIKE '%bigquery%'\n",
    "                \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigquery_experts_query = \"\"\"\n",
    "                         SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "                         FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "                         INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                             ON q.id = a.parent_Id\n",
    "                         WHERE q.tags LIKE '%bigquery%'\n",
    "                         GROUP BY a.owner_user_id\n",
    "                         \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expert_finder(topic, client):\n",
    "    '''\n",
    "    Returns a DataFrame with the user IDs who have written Stack Overflow answers on a topic.\n",
    "\n",
    "    Inputs:\n",
    "        topic: A string with the topic of interest\n",
    "        client: A Client object that specifies the connection to the Stack Overflow dataset\n",
    "\n",
    "    Outputs:\n",
    "        results: A DataFrame with columns for user_id and number_of_answers. Follows similar logic to bigquery_experts_results shown above.\n",
    "    '''\n",
    "    my_query = \"\"\"\n",
    "               SELECT a.owner_user_id AS user_id, COUNT(1) AS number_of_answers\n",
    "               FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
    "               INNER JOIN `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
    "                   ON q.id = a.parent_Id\n",
    "               WHERE q.tags like '%{topic}%'\n",
    "               GROUP BY a.owner_user_id\n",
    "               \"\"\"\n",
    "\n",
    "    # Set up the query (a real service would have good error handling for \n",
    "    # queries that scan too much data)\n",
    "    safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)      \n",
    "    my_query_job = client.query(my_query, job_config=safe_config)\n",
    "\n",
    "    # API request - run the query, and return a pandas DataFrame\n",
    "    results = my_query_job.to_dataframe()\n",
    "\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
